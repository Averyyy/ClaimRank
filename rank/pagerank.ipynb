{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "测试用的csv文件："
      ],
      "metadata": {
        "id": "S_OcvjTjw7oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "id1,id2,relation\n",
        "1001,2001,support\n",
        "1002,2001,refute\n",
        "1003,2002,support\n",
        "1002,2003,refute\n",
        "1004,2001,support\n",
        "1005,2004,refute\n",
        "'''"
      ],
      "metadata": {
        "id": "a9AjBZsPWFOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUZq-zwMHeGI",
        "outputId": "207e0106-f774-468d-f487-833a91286ef9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "目前写的是把relations视作doc间的relationship，也就是id1, id2说的是文档1和2。\n",
        "\n",
        "但是实际Libo写的要求是relations描述的是claim。\n",
        "\n",
        "我还没想明白怎么把claim映射到docs来做一系列的公式计算，是不是应该利用claims relation 计算出两篇文档的相似值来构造出doc relation（如果是支持则为正数，反对则为负数），然后再利用以下的代码进行迭代更新doc的信任score？"
      ],
      "metadata": {
        "id": "WfIxQE7bt_v7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vEDTgwO9Mmro"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def customized_pagerank(relations_df, max_iterations=100, alpha=0.85, tolerance=1e-6):\n",
        "    \"\"\"\n",
        "    多加了两个argument：\n",
        "      alpha: 阻尼因子\n",
        "      tolerance: 收敛值\n",
        "\n",
        "    返回：各文档的信任得分\n",
        "    \"\"\"\n",
        "    # 提取所有的文档 ID\n",
        "    document_ids = set(relations_df['id1']).union(set(relations_df['id2']))\n",
        "    document_ids = sorted(document_ids)\n",
        "    doc_index = {doc_id: idx for idx, doc_id in enumerate(document_ids)}  # {1001: 0, 1002: 1, 1003: 2, 2001: 3}\n",
        "    index_doc = {idx: doc_id for doc_id, idx in doc_index.items()}     # {0: 1001, 1: 1002, 2: 1003, 3: 2001}\n",
        "    N = len(document_ids)\n",
        "\n",
        "    # 初始化信任度向量 s_d0\n",
        "    s = np.full(N, 0.5)\n",
        "    s0 = s.copy()\n",
        "\n",
        "    trusted_docs = []  # 这里添加手动标注过的可信文档的ID列表（初始值是1，不确定的保留0.5）\n",
        "    for doc_id in trusted_docs:\n",
        "        idx = doc_index[doc_id]\n",
        "        s[idx] = 1.0\n",
        "        s0[idx] = 1.0\n",
        "\n",
        "    # 正向和负向的 adjacency matrix\n",
        "    W_plus = np.zeros((N, N))\n",
        "    W_minus = np.zeros((N, N))\n",
        "\n",
        "    for _, row in relations_df.iterrows():\n",
        "        id1 = row['id1']\n",
        "        id2 = row['id2']\n",
        "        relation = row['relation']\n",
        "        i = doc_index[id1]\n",
        "        j = doc_index[id2]\n",
        "        if relation == 'support': # 后期改成数值\n",
        "            W_plus[i, j] += 1\n",
        "        elif relation == 'refute': # 后期改成数值\n",
        "            W_minus[i, j] += 1\n",
        "\n",
        "    # 计算每个文档的正向和负向权重总和\n",
        "    W_plus_sum = W_plus.sum(axis=0)\n",
        "    W_minus_sum = W_minus.sum(axis=0)\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        s_prev = s.copy()\n",
        "        P_pos = np.zeros(N)\n",
        "        N_neg = np.zeros(N)\n",
        "\n",
        "        # 正负向影响\n",
        "        for d in range(N):\n",
        "            if W_plus_sum[d] > 0:\n",
        "                P_pos[d] = np.dot(W_plus[:, d], s_prev) / W_plus_sum[d]\n",
        "            else:\n",
        "                P_pos[d] = 0\n",
        "\n",
        "            if W_minus_sum[d] > 0:\n",
        "                N_neg[d] = np.dot(W_minus[:, d], s_prev) / W_minus_sum[d]\n",
        "            else:\n",
        "                N_neg[d] = 0\n",
        "\n",
        "        # 净影响 + 映射\n",
        "        I = P_pos - N_neg\n",
        "        f_I = (I + 1) / 2\n",
        "        s = (1 - alpha) * s0 + alpha * f_I\n",
        "\n",
        "        # convergence\n",
        "        delta = np.linalg.norm(s - s_prev, ord=1)\n",
        "        if delta < tolerance:\n",
        "            print(f'迭代在第 {iteration+1} 次时收敛，变化量 {delta}')\n",
        "            break\n",
        "\n",
        "    scores = {index_doc[idx]: s[idx] for idx in range(N)}\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relations_df = pd.read_csv('/content/drive/My Drive/546 Project/relations.csv')\n",
        "scores = customized_pagerank(relations_df, max_iterations=100)\n",
        "for doc_id, score in scores.items():\n",
        "    print(f'文档 {doc_id} 的信任得分为 {score:.4f}')"
      ],
      "metadata": {
        "id": "Zklbn0akWKq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c51cbbf-5ecd-44d6-af4e-950620b8925d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "迭代在第 2 次时收敛，变化量 0.0\n",
            "文档 1001 的信任得分为 0.5000\n",
            "文档 1002 的信任得分为 0.5000\n",
            "文档 1003 的信任得分为 0.5000\n",
            "文档 1004 的信任得分为 0.5000\n",
            "文档 1005 的信任得分为 0.5000\n",
            "文档 2001 的信任得分为 0.5000\n",
            "文档 2002 的信任得分为 0.7125\n",
            "文档 2003 的信任得分为 0.2875\n",
            "文档 2004 的信任得分为 0.2875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "其他问题：\n",
        "如果两个文档与其他具有已知信任度的文档没有连接，那么由于初始信任度相同，且彼此的影响对等，迭代更新后，信任度可能没啥变化。"
      ],
      "metadata": {
        "id": "E-kO_fMNWexI"
      }
    }
  ]
}